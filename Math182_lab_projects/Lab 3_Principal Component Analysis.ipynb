{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Due date: Tuesday 02/25 at 11.59 pm ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Principal Component Analysis\n",
    "\n",
    "In this lab assignment, we will walk through an example of using Principal Component Analysis (PCA) on a dataset involving [iris plants](https://en.wikipedia.org/wiki/Iris_(plant)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, run the following cell to load the dataset into this notebook. \n",
    "* `iris_features` will contain a numpy array of 4 attributes for 150 different plants (shape 150 x 4). This is the matrix onto which we are going to apply PCA. To follow the lecture notes, we are going to traspose it to have shape 4x150. \n",
    "* `iris_target` will contain the class of each plant. There are 3 classes of plants in the dataset: Iris-Setosa, Iris-Versicolour, and Iris-Virginica. The class names will be stored in `iris_target_names`.\n",
    "* `iris_feature_names` will be a list of 4 names, one for each attribute in `iris_features`. \n",
    "\n",
    "Additional information on the dataset will be included in the description printed at the end of the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = load_iris() # Loading the dataset\n",
    "\n",
    "# Unpacking the data into arrays\n",
    "iris_features = iris_data['data']\n",
    "iris_target = iris_data['target']\n",
    "iris_feature_names = iris_data['feature_names']\n",
    "iris_target_names = iris_data['target_names']\n",
    "\n",
    "# Convert iris_target to string labels instead of int labels currently (0, 1, 2) for the classes\n",
    "iris_target = iris_target_names[iris_target]\n",
    "\n",
    "#traspose iris_features to have shape mxN\n",
    "iris_features=iris_features.T\n",
    "iris_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the data by creating a scatter matrix of our iris features. To do this, we'll create 2D scatter plots for every possible pair of our four features. This should result in six total scatter plots in our scatter matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "plt.suptitle(\"Scatter Matrix of Iris Features\")\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "for i in range(1, 4):\n",
    "    for j in range(i):\n",
    "        plt.subplot(3, 3, i+3*j)\n",
    "        sns.scatterplot(iris_features[i,: ], iris_features[j, :], hue=iris_target) # SOLUTION\n",
    "        plt.xlabel(iris_feature_names[i])\n",
    "        plt.ylabel(iris_feature_names[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1a\n",
    "\n",
    "To apply PCA, we will first need to \"center\" the data so that the mean of each feature is 0. Additionally, we will need to scale the centered data by $\\frac{1}{\\sqrt n}$, where $n$ is the number of samples (rows) we have in our dataset. \n",
    "\n",
    "Compute the rowise mean of `iris_features` in the cell below and store it in `iris_mean` (should be a numpy array of 4 means, 1 for each attribute). Then, subtract `iris_mean` from `iris_features`, divide the result by the $\\sqrt n$, and save the result in `normalized_features`.\n",
    "\n",
    "**Hints:** \n",
    "* Use `np.mean` or `np.average` to compute `iris_mean`, and pay attention to the `axis` argument.\n",
    "* If you are confused about how numpy deals with arithmetic operations between arrays of different shapes, see this note about [broadcasting](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html) for explanations/examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#student\n",
    "n = ... # should be 150\n",
    "iris_mean = ...\n",
    "iris_mean.shape=(iris_mean.size,1)  #just fixing the vector to be two dimensional to be able to perform the next calculation\n",
    "normalized_features = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "n = iris_features.shape[1] # should be 150\n",
    "iris_mean = np.mean(iris_features, axis=1) \n",
    "iris_mean.shape=(iris_mean.size,1)\n",
    "normalized_features = (iris_features - iris_mean) / np.sqrt(n) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1b\n",
    "\n",
    "As you may recall from lecture, PCA is a specific application of the singular value decomposition (SVD) for matrices. In the following cell, let's use the [`np.linalg.svd`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.svd.html) function compute the SVD of our `normalized_features`. Store the left singular vectors, singular values, and right singular vectors in `u`, `s`, and `vt` respectively.\n",
    "\n",
    "**Hint:** Set the `full_matrices` argument of `np.linalg.svd` to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#student\n",
    "u, s, vt = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "u, s, vt = np.linalg.svd(normalized_features, full_matrices=False) # SOLUTION\n",
    "u.shape, s, vt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1c\n",
    "\n",
    "What can we learn from the singular values in `s`? First, we can compute the total variance of the data by summing the squared singular values. We will later be able to use this value to determine the variance captured by a subset of our principal components.\n",
    "\n",
    "Compute the total variance below and store the result in the variable `total_variance`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#student\n",
    "total_variance = ...\n",
    "print(\"total_variance: {:.3f} should approximately equal the sum of feature variances: {:.3f}\"\n",
    "      .format(..., ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "total_variance = np.sum(np.square(s)) # SOLUTION\n",
    "print(\"total_variance: {:.3f} should approximately equal the sum of feature variances: {:.3f}\"\n",
    "      .format(total_variance, np.sum(np.var(iris_features, axis=1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2a\n",
    "\n",
    "Let's now use only the first two principal components to see what a 2D version of our iris data looks like.\n",
    "Print the first two principal components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "u[:,np.array((0,1))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is then the best 2-dimensional affine subspace? Remember that to define an affine subspace you need to specify the translation vector ($\\mu$ in your lecture notes) and a matrix $Q$ with as columns a basis for the subspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#student\n",
    "mu=...\n",
    "Q=\n",
    "print(mu,Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "mu=iris_mean\n",
    "Q=u[:,np.array((0,1))]\n",
    "print(mu,Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the rank-2 principal coordinates of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#student\n",
    "beta = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "beta_2d = np.dot(Q.T,np.sqrt(n)*normalized_features) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the rank-2 principal mean of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#student\n",
    "beta_bar=..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "beta_bar=np.dot(Q.T,iris_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct now the 2D version of the iris data finding the rank-2 principal coordinates shifted by the rank-2 principal mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#student\n",
    "iris_2d=..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "iris_2d=beta_2d+beta_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the cell below to create the scatter plot of our 2D version of the iris data, `iris_2d`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "plt.title(\"PC2 vs. PC1 for Iris Data\")\n",
    "plt.xlabel(\"Iris PC1\")\n",
    "plt.ylabel(\"Iris PC2\")\n",
    "sns.scatterplot(iris_2d[0, :], iris_2d[1, :], hue=iris_target);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2b\n",
    "\n",
    "What do you observe about the plot above? If you were given a point in the subspace defined by PC1 and PC2, how well would you be able to classify the point as one of the three iris types?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#student"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION:** The setosa class is still separated from the other two classes, and there is some slight overlap between the other two classes. Perfect classification between the versicolor and verginica classes would be hard using this representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2c\n",
    "\n",
    "What proportion of the total variance is accounted for when we project the iris data down to two dimensions? Compute this quantity in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "two_dim_variance = np.sum(np.square(s[:2])) / total_variance \n",
    "two_dim_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "As a last step, let's create a [scree plot](https://en.wikipedia.org/wiki/Scree_plot) to visualize the weight of each of each principal component. In the cell below, create a scree plot by plotting a line plot of the square of the singular values in `s` vs. the principal component number (1st, 2nd, 3rd, or 4th).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#student\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "plt.xlabel(\"Principal Component\")\n",
    "plt.ylabel(\"Variance (Component Scores)\")\n",
    "plt.title(\"Scree Plot of Iris Principal Components\")\n",
    "plt.plot([1, 2, 3, 4], ...);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "plt.xlabel(\"Principal Component\")\n",
    "plt.ylabel(\"Variance (Component Scores)\")\n",
    "plt.title(\"Scree Plot of Iris Principal Components\")\n",
    "plt.plot([1, 2, 3, 4], np.square(s));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Instructions ##\n",
    "\n",
    "Many assignments throughout the course will have a written portion and a code portion. Please follow the directions below to properly submit both portions.\n",
    "\n",
    "### Written Portion ###\n",
    "*  Scan all the pages into a PDF. You can use any scanner or a phone using applications such as CamScanner. Please **DO NOT** simply take pictures using your phone. \n",
    "* **Please start a new page for each PART**. If you have already written multiple questions on the same page, you can crop the image in CamScanner or fold your page over (the old-fashioned way). This helps expedite grading.\n",
    "* It is your responsibility to check that all the work on all the scanned pages is legible.\n",
    "\n",
    "### Code Portion ###\n",
    "* Save your notebook using File > Save and Checkpoint.\n",
    "* Use File > Downland as > PDF via Latex.\n",
    "* Download the PDF file and confirm that none of your work is missing or cut off. \n",
    "### Submitting ###\n",
    "* Combine the PDFs from the written and code portions into one PDF.  [Here](https://smallpdf.com/merge-pdf) is a useful tool for doing so.  \n",
    "* Submit the assignment to Lab3 on Gradescope. \n",
    "* **Make sure to assign each page of your pdf to the correct question.**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
